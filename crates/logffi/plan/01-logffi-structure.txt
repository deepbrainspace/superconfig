Approach 1: Truly Unified Interface (Hidden Dependencies)

  # Cargo.toml - Users ONLY need this
  [dependencies]
  logffi = "0.2"  # That's it! No other imports needed

  use logffi::prelude::*;

  fn main() {
      // Configure destinations without importing anything else
      logffi::init()
          .console()
          .file("app.log")
          .rotating_file("debug.log", "10 MB")
          .json_file("structured.log")
          .apply()?;

      // Basic logging
      info!("Starting application");

      // Tracing features automatically available
      let span = span!(Level::INFO, "database_operation");
      let _enter = span.enter();

      // Structured logging
      info!(user_id = 123, action = "login", "User logged in");

      // Error handling
      define_errors! {
          pub enum AppError {
              #[error("Database connection failed", level = error)]
              DatabaseError {
                  #[source]
                  cause: std::io::Error
              },
          }
      }

      // Everything just works!
  }

  Implementation approach:
  // logffi would bundle common destinations
  #[cfg(feature = "log")]
  pub mod destinations {
      pub struct Console {
          inner: env_logger::Builder
      }

      pub struct File {
          inner: fern::Dispatch
      }

      pub struct RotatingFile {
          inner: log4rs::Config
      }
  }

  #[cfg(feature = "tracing")]
  pub mod destinations {
      pub struct Console {
          inner: tracing_subscriber::fmt::Layer
      }

      pub struct JsonFile {
          inner: tracing_subscriber::fmt::Layer<JsonStorage>
      }
  }

  Approach 2: Transparent Pass-Through (Current Design)

  # Users configure their preferred logger
  [dependencies]
  logffi = { version = "0.2", features = ["tracing"] }
  tracing-subscriber = "0.3"  # Need this for configuration

  use logffi::{info, error, define_errors};

  fn main() {
      // Configure tracing yourself
      tracing_subscriber::fmt()
          .json()
          .init();

      // Use LogFFI macros - they route to tracing
      info!("This goes to tracing");
  }

  The Key Question: Which Adds More Value?

  Unified Interface Pros:

  - One import - Super clean for users
  - Discoverable - IDE shows all options
  - Consistent API - Same config style everywhere
  - No confusion - Clear that LogFFI handles it all

  Unified Interface Cons:

  - Maintenance burden - Need to wrap many libraries
  - Version conflicts - We control dependency versions
  - Limited flexibility - Can't use latest features immediately
  - Bloated binary - Bundle features user might not need

  My Recommendation: Hybrid Approach

  // logffi provides common cases built-in
  pub mod easy {
      pub fn init_console() { /* sets up console logging */ }
      pub fn init_json_file(path: &str) { /* json logging */ }
      pub fn init_development() { /* pretty console output */ }
      pub fn init_production() { /* json + file rotation */ }
  }

  // But also allows manual configuration
  impl LogFFI {
      pub fn custom<F>(f: F) where F: FnOnce() {
          // User configures their logger
          f();
          // We detect what was configured
      }
  }

  Usage examples:

  // EASY MODE - 90% of users
  use logffi::prelude::*;

  fn main() {
      // One line setup
      logffi::easy::init_development();

      // Everything works
      info!("Starting up");

      let span = span!(Level::DEBUG, "processing");
      let _guard = span.enter();

      error!("Something failed");
  }

  // ADVANCED MODE - Power users
  use logffi::prelude::*;

  fn main() {
      // Custom configuration
      logffi::custom(|| {
          tracing_subscriber::fmt()
              .with_env_filter("my_app=debug,hyper=warn")
              .json()
              .with_span_events(FmtSpan::CLOSE)
              .init();
      });

      // Same unified interface
      info!("Configured with custom settings");
  }

  Client Usage Examples

  Example 1: Library Author

  // my_database_lib/src/lib.rs
  use logffi::prelude::*;

  define_errors! {
      pub enum DbError {
          #[error("Connection timeout", level = error, code = "DB001")]
          Timeout { duration: Duration },

          #[error("Query failed", level = warn, code = "DB002")]
          QueryError {
              query: String,
              #[source]
              cause: sqlx::Error,
          },
      }
  }

  pub async fn connect(url: &str) -> Result<Connection, DbError> {
      info!(target: "db", "Attempting connection to {}", url);

      let span = span!(Level::DEBUG, "db_connect", url = %url);
      let _enter = span.enter();

      // Automatic logging on error
      sqlx::connect(url)
          .await
          .map_err(|e| DbError::new_timeout(Duration::from_secs(30)))
  }

  Example 2: Application Developer

  use logffi::prelude::*;

  fn main() -> Result<(), Box<dyn Error>> {
      // Pick your setup style
      #[cfg(debug_assertions)]
      logffi::easy::init_development();  // Pretty console

      #[cfg(not(debug_assertions))]
      logffi::easy::init_production();   // JSON + rotation

      let span = span!(Level::INFO, "app_lifecycle");
      let _enter = span.enter();

      info!("Application starting");

      // Structured logging works automatically
      info!(
          version = env!("CARGO_PKG_VERSION"),
          pid = std::process::id(),
          "Process initialized"
      );

      // Errors are logged automatically
      if let Err(e) = risky_operation() {
          // The error was already logged by define_errors!
          return Err(e.into());
      }

      Ok(())
  }

  Example 3: FFI User

  // When compiling for Python
  use logffi::prelude::*;

  #[pyfunction]
  fn setup_logging(py: Python, handler: PyObject) {
      // Initialize FFI bridge
      logffi::ffi::set_python_handler(handler);

      // Now all Rust logs go to Python
      info!("Rust library initialized");
  }

  #[pyfunction]
  fn process_data(data: Vec<u8>) -> PyResult<Vec<u8>> {
      let span = span!(Level::INFO, "process_data", size = data.len());
      let _enter = span.enter();

      info!("Processing {} bytes", data.len());

      // Any errors are automatically logged AND mapped to Python
      let result = internal_process(data)
          .map_err(|e| PyErr::new::<pyo3::exceptions::PyRuntimeError, _>(
              format!("{}: {}", e.code(), e)
          ))?;

      info!("Processing complete");
      Ok(result)
  }

  The Value Proposition

  With this hybrid approach, LogFFI provides:

  1. Easy mode for 90% of use cases - One-line setup
  2. Power mode for advanced users - Full control
  3. Unified macro interface - Same API regardless of backend
  4. Automatic span support - Get tracing features with log backend
  5. Enhanced errors - Always available
  6. FFI bridge - When needed

